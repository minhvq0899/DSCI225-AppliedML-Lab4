{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    " \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing code (contextmanager)\n",
    "\n",
    "(borrowed from https://stackoverflow.com/questions/7370801/measure-time-elapsed-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11968400000478141\n",
      "0.23295649999636225\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer() as my_timer:\n",
    "    sum = 0\n",
    "    for x in range(1000000):\n",
    "        sum += x\n",
    "    print(my_timer())\n",
    "    for x in range(1000000):\n",
    "        sum += x\n",
    "    print(my_timer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  You might want to go investigate how they work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What I found online**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any programming language, the usage of resources like file operations or database connections is very common. But these resources are limited in supply. Therefore, the main problem lies in making sure to release these resources after usage. If they are not released then it will lead to resource leakage and may cause the system to either slow down or crash. It would be very helpful if user have a mechanism for the automatic setup and teardown of resources.In Python, it can be achieved by the usage of context managers which facilitate the proper handling of resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To my understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Manager is a way to manage resource in you laptop. You can call it from the library contextlib and then use it with the key word \"with\". \n",
    "\n",
    "The format is: \n",
    "with (built-in function) as (variable name):\n",
    "    sum = 0\n",
    "    for x in range(1000000):\n",
    "        sum += x\n",
    "    print((variable name))\n",
    "    for x in range(1000000):\n",
    "        sum += x\n",
    "    print((variable name))\n",
    "    \n",
    "where the built-in function can be many different functions where you manage time, memory, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install scitime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scitime in c:\\users\\minhv\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scitime) (0.20.1)\n",
      "Requirement already satisfied: pandas>=0.20.3 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scitime) (0.23.4)\n",
      "Requirement already satisfied: joblib>=0.12.5 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scitime) (0.14.1)\n",
      "Requirement already satisfied: psutil>=5.4.7 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scitime) (5.4.8)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->scitime) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->scitime) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from pandas>=0.20.3->scitime) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from pandas>=0.20.3->scitime) (2018.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minhv\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.20.3->scitime) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scitime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I came to this part the last so let's use this package to compare the estimate run time of sgd_clf with its actual run time.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sgd_clf.fit took 142.129 secs\n",
    "\n",
    "Let's see how long does scitime guesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SGDClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2c64083b8095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# run the estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mestimation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_clf_scitime_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scitime\\estimate.py\u001b[0m in \u001b[0;36m_estimate\u001b[1;34m(self, algo, X, y)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \"\"\"\n\u001b[0;32m    371\u001b[0m         \u001b[1;31m# fetching sklearn model of the end user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[0mparam_dic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_algo_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[0malgo_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scitime\\estimate.py\u001b[0m in \u001b[0;36m_fetch_algo_metadata\u001b[1;34m(algo)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0malgo_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0malgo_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         param_dic = {'name': algo_name,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scitime\\_utils.py\u001b[0m in \u001b[0;36mconfig\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_config.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SGDClassifier'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import time\n",
    "from scitime import Estimator\n",
    "\n",
    "# example for rf regressor\n",
    "estimator = Estimator(meta_algo='RF', verbose=3)\n",
    "sgd_clf_scitime_test = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# run the estimation\n",
    "estimation, lower_bound, upper_bound = estimator._estimate(sgd_clf_scitime_test, X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"The 95% confidence interval is: \" + str(lower_bound) + \"-\" + str(upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops this doesn't work because scitime does not support SGDClassifier.\n",
    "\n",
    "Let's try SVC.\n",
    "\n",
    "Below, svm_clf.fit took 31.488 secs to fit 4000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval is: 0.0017998039722442627-0.2910521030426025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# example for rf regressor\n",
    "estimator = Estimator(meta_algo='RF', verbose=0)\n",
    "svm_clf_scitime = SVC(gamma=\"auto\", random_state=42)\n",
    "\n",
    "# run the estimation\n",
    "estimation, lower_bound, upper_bound = estimator.time(svm_clf_scitime, X_train[:4000], y_train[:4000])\n",
    "\n",
    "print(\"The 95% confidence interval is: \" + str(lower_bound) + \"-\" + str(upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this mean that it predicts that it will take from 0.001 second to 0.1 to 29 seconds rouughly? \n",
    "\n",
    "Because if it does, it's pretty close to the actual time (31 seconds). \n",
    "\n",
    "This package is only useful if your algo is fitting a really large training dataset because our 95 confidence interval is super wide. Overall, this is a cool package that can become handy in my independent study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "some_digit = X[0]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification\n",
    "\n",
    "Starting Out\n",
    "\n",
    "- Note the timing code near the top and the example of how to use it. This is what Python calls a \"context manager.\" It's a good trick and you might want to go investigate how they work.\n",
    "- Observe that the code is using \"svm_clf.fit(X_train[:1000], y_train[:1000])\" for training some models. Make sure you understand what that means and consider why things might have been done that way.\n",
    "- Further down, find the place where the code is fitting an SGDClassifier to the entire training set for MNIST. See how long that takes on your machine.\n",
    "- Wrap the training for the SVC and OneVsRestClassifiers in timing constructs so you can see how long they take. Then conduct some experiments in which you try successively larger amounts of training data, doubling the size a few times to get a sense of the underlying complexity. You probably want to set up these experiments so they complete without interaction and then run them while you go read your book (or take a long nap :-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_clf 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_clf.fit took 1.871 secs to fit 1000 observations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "with elapsed_timer() as sgd_timer:\n",
    "    svm_clf.fit(X_train[:1000], y_train[:1000]) \n",
    "print(f\"svm_clf.fit took {sgd_timer():.3f} secs to fit 1000 observations\")\n",
    "\n",
    "svm_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why things might have been done that way**\n",
    "\n",
    "Note: You are only using the first 1000 observations to fit the svm for 2 reasons (in my opinion):\n",
    "\n",
    "- You might want to save the other 5k for dev dataset\n",
    "- It takes much less time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_clf 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_clf.fit took 7.587 secs to fit 2000 observations\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer() as sgd_timer:\n",
    "    svm_clf.fit(X_train[:2000], y_train[:2000]) \n",
    "print(f\"svm_clf.fit took {sgd_timer():.3f} secs to fit 2000 observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_clf 4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_clf.fit took 31.488 secs to fit 4000 observations\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer() as sgd_timer:\n",
    "    svm_clf.fit(X_train[:4000], y_train[:4000]) \n",
    "print(f\"svm_clf.fit took {sgd_timer():.3f} secs to fit 4000 observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_obs</th>\n",
       "      <th>Time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>7.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>31.488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_obs  Time_taken\n",
       "0           1000       1.871\n",
       "1           2000       7.587\n",
       "2           4000      31.488"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'Number_of_obs': [1000, 2000, 4000], 'Time_taken': [1.871, 7.587, 31.488]}\n",
    "SVM_timer_df = pd.DataFrame(data=d)\n",
    "SVM_timer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17202263780>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(SGD_timer_df['Number_of_obs'], SGD_timer_df['Time_taken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok we can kinda see that the complexity of SVC is cubic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVR_clf 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr_clf.fit took 10.335 secs to fit 1000 observations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
    "\n",
    "with elapsed_timer() as ovr_timer:\n",
    "    ovr_clf.fit(X_train[:1000], y_train[:1000])\n",
    "print(f\"ovr_clf.fit took {ovr_timer():.3f} secs to fit 1000 observations\")\n",
    "\n",
    "ovr_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVR_clf 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr_clf.fit took 39.693 secs to fit 2000 observations\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer() as ovr_timer:\n",
    "    ovr_clf.fit(X_train[:2000], y_train[:2000])\n",
    "print(f\"ovr_clf.fit took {ovr_timer():.3f} secs to fit 2000 observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVR_clf 4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr_clf.fit took 155.305 secs to fit 1000 observations\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer() as ovr_timer:\n",
    "    ovr_clf.fit(X_train[:4000], y_train[:4000])\n",
    "print(f\"ovr_clf.fit took {ovr_timer():.3f} secs to fit 4000 observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_obs</th>\n",
       "      <th>Time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>10.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>39.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>155.305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_obs  Time_taken\n",
       "0           1000      10.335\n",
       "1           2000      39.693\n",
       "2           4000     155.305"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ovr = {'Number_of_obs': [1000, 2000, 4000], 'Time_taken': [10.335, 39.693, 155.305 ]}\n",
    "OVR_timer_df = pd.DataFrame(data=d_ovr)\n",
    "OVR_timer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17200ae5278>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(OVR_timer_df['Number_of_obs'], OVR_timer_df['Time_taken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneVsRestClassifier has the complexity of square**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are fitting an SGDClassifier to the entire training set for MNIST. See how long that takes on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_clf.fit took 142.129 secs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with elapsed_timer() as sgd_timer:\n",
    "    sgd_clf.fit(X_train, y_train)\n",
    "print(f\"sgd_clf.fit took {sgd_timer():.3f} secs\")\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It takes more than 2 minutes for SGDClassifier to fit the whole train dataset of 50k observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-15955.22627845, -38080.96296175, -13326.66694897,\n",
       "           573.52692379, -17680.6846644 ,   2412.53175101,\n",
       "        -25526.86498156, -12290.15704709,  -7946.05205023,\n",
       "        -10631.35888549]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8489802 , 0.87129356, 0.86988048])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89707059, 0.8960948 , 0.90693604])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-4f02f856ef3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconf_mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf_mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    775\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[0;32m    776\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[1;32m--> 777\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[1;31m# Concatenate the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    741\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self._max_iter,\n\u001b[1;32m--> 596\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         if (self._tol is not None and self._tol > -np.inf\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    548\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m                                  max_iter=max_iter)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             self._fit_binary(X, y, alpha=alpha, C=C,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_multiclass\u001b[1;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m    648\u001b[0m                                 \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m                                 validation_mask=validation_mask)\n\u001b[1;32m--> 650\u001b[1;33m             for i in range(len(self.classes_)))\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;31m# take the maximum of n_iter_ over every binary fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask)\u001b[0m\n\u001b[0;32m    444\u001b[0m                            \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                            \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                            est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "with elapsed_timer() as cv_predict:\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx\n",
    "\n",
    "print(f\"cross_val_predict took {cv_predict():.3f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with elapsed_timer() as cv_predict:\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx\n",
    "\n",
    "print(f\"cross_val_predict took {cv_predict():.3f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Things Up, pt. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the image on p. 199 of the book (or find the same in the notebook for chapter 7). This suggests that maybe we could train and predict on a smaller image and still do pretty well. Begin by just removing pixels around the edges of the image - how many is up to you. Hint: reshape the image from (784,) to (28, 28) and then use Numpy slicing (that's the : operator) to do this, then reshape back to one dimension. Remember to do the same thing when you predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's reshape our dataset in a totally differetn dataset (for safety)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e6e5aaadc687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hum let's try something with the first 4 obs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 784)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_experiment = X_train[:4]\n",
    "X_train_experiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_experiment = y_train[:4]\n",
    "y_train_experiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (28,28) into shape (784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-73d4482f3aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_experiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_train_experiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_experiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_experiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (28,28) into shape (784)"
     ]
    }
   ],
   "source": [
    "for i in range (len(X_train_experiment)): \n",
    "    X_train_experiment[i] = np.reshape(X_train_experiment[i], (28,28))\n",
    "    \n",
    "X_train_experiment.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hum does not really work. Let's try take that row out, reshape it and then put it back in a different narray.**\n",
    "**And this time, let's work with python array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3d = []\n",
    "\n",
    "for i in range (len(X_train_experiment)): \n",
    "    one_digit = X_train_experiment[i]\n",
    "    one_digit = one_digit.reshape(28,28)\n",
    "    X_train_3d.append(one_digit)\n",
    "    \n",
    "len(X_train_3d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_3d[0]))\n",
    "print(len(X_train_3d[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so it seems like we are having an array of arrays of arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's say we only want 18 pixels in the middle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(X_train_3d)): \n",
    "    X_train_3d[i] = X_train_3d[i][5:23,5:23]\n",
    "    \n",
    "print(len(X_train_3d))\n",
    "print(len(X_train_3d[0]))\n",
    "print(len(X_train_3d[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X_train_experiment_final = np.array([])\n",
    "\n",
    "for i in range (len(X_train_3d)): \n",
    "    one_digit = X_train_3d[i]\n",
    "    omgiwanttosleep = np.array(one_digit)\n",
    "    omgiwanttosleep = np.reshape(omgiwanttosleep, 324)\n",
    "    X_train_experiment_final = np.concatenate((X_train_experiment_final,omgiwanttosleep))\n",
    "    \n",
    "    \n",
    "print(X_train_experiment_final.shape)\n",
    "print(X_train_experiment_final.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_experiment_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_experiment_final = np.reshape(X_train_experiment_final, (len(X_train_3d), 324))\n",
    "\n",
    "X_train_experiment_final.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 324)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_experiment_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   3.  18.  18.  18. 126. 136. 175.\n",
      "   26. 166. 255. 247.   0.   0.   0.  30.  36.  94. 154. 170. 253. 253.\n",
      "  253. 253. 253. 225. 172. 253. 242. 195.   0.   0.  49. 238. 253. 253.\n",
      "  253. 253. 253. 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.\n",
      "   18. 219. 253. 253. 253. 253. 253. 198. 182. 247. 241.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.  11.   0.  43.\n",
      "  154.   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.\n",
      "   90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 139. 253. 190.   2.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.  11. 190. 253.  70.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241. 225.\n",
      "  160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  81. 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  45. 186. 253. 253. 150.  27.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  16.  93.\n",
      "  252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.  46. 130. 183. 253. 253. 207.   2.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  39. 148. 229. 253. 253. 253. 250.\n",
      "  182.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253. 253.\n",
      "  253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213.\n",
      "  253. 253. 253. 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.  18.\n",
      "  171. 219. 253. 253. 253. 253. 195.  80.   9.   0.   0.   0.   0.   0.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 252.\n",
      "  237.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54. 227.\n",
      "  253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.   0.\n",
      "   10.  60. 224. 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.\n",
      "    0.   0.   0.   0. 163. 252. 252. 252. 253. 252. 252.  96. 189. 253.\n",
      "  167.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253. 190. 114. 253.\n",
      "  228.  47.  79. 255. 168.   0.   0.   0.   0.   0.  48. 238. 252. 252.\n",
      "  179.  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.  38.\n",
      "  165. 253. 233. 208.  84.   0.   0.   0.   0.   0.   0. 253. 252. 165.\n",
      "    0.   0.   7. 178. 252. 240.  71.  19.  28.   0.   0.   0.   0.   0.\n",
      "    0. 253. 252. 195.   0.   0.  57. 252. 252.  63.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0. 253. 252. 195.   0.   0. 198. 253. 190.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.  76.\n",
      "  246. 252. 112.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 253.\n",
      "  252. 148.   0.  85. 252. 230.  25.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   7. 135. 253. 186.  12.   0.  85. 252. 223.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.  85. 252. 145.\n",
      "    0.   0.   0.   0.   0.   0.   0.  48. 165. 252. 173.   0.   0.   0.\n",
      "    0.  86. 253. 225.   0.   0.   0.   0.   0.   0. 114. 238. 253. 162.\n",
      "    0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178. 225.\n",
      "  253. 223. 167.  56.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229.\n",
      "  215. 252. 252. 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.  28.\n",
      "  199. 252. 252. 253. 252. 252. 233. 145.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  67. 232.  39.  81.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0. 120. 180.  39. 163.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   2. 153. 210.  40. 163.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  27. 254.\n",
      "  162.   0. 163.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 183. 254. 125.   0. 163.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0. 198. 254.  56.   0. 163.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.  23. 231. 254.  29.   0.\n",
      "  120.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163.\n",
      "  254. 216.  16.   0.  67.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   14.  86. 178. 248. 254.  91.   0.   0.  85.   0.   0.   0.  47.  49.\n",
      "  116. 144. 150. 241. 243. 234. 179. 241. 252.  40.   0.   0. 237. 207.\n",
      "  207. 207. 253. 254. 250. 240. 198. 143.  91.  28.   5. 233. 250.   0.\n",
      "    0.   0. 177. 177. 177. 177. 177.  98.  56.   0.   0.   0.   0.   0.\n",
      "  102. 254. 220.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0. 169. 254. 137.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 169. 254.  57.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169. 254.\n",
      "   57.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 169. 255.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0. 169. 254.  96.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169. 254. 153.   0.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 124.\n",
      "  253. 255.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  96. 244. 251. 253.  62.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0. 127. 251. 251. 253.  62.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.  68. 236. 251. 211.  31.\n",
      "    8.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  60. 228.\n",
      "  251. 251.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 155. 253. 253. 189.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.  20. 253. 251. 235.  66.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.  32. 205. 253. 251. 126.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 104. 251.\n",
      "  253. 184.  15.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  80. 240. 251. 193.  23.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.  32. 253. 253. 253. 159.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 151. 251. 251. 251.  39.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 221. 251.\n",
      "  251. 172.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 234. 251. 251. 196.  12.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0. 253. 251. 251.  89.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 159. 255. 253. 253.  31.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 228. 253.\n",
      "  247. 140.   8.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  64. 251. 253. 220.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(X_train_experiment_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so it seems like we get what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_train_experiment.shape)\n",
    "print(y_train_experiment.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1], dtype=uint8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_clf.fit took 0.535 secs to fit 4 obs\n"
     ]
    }
   ],
   "source": [
    "sgd_clf_18pixel_experiment = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "with elapsed_timer() as sgd_timer_experiment:\n",
    "    sgd_clf_18pixel_experiment.fit(X_train_experiment_final, y_train_experiment)\n",
    "print(f\"sgd_clf.fit took {sgd_timer_experiment():.3f} secs to fit 4 obs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify some_digit so we can test with it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(324,)\n"
     ]
    }
   ],
   "source": [
    "# Reshape it into 28x28\n",
    "some_digit = np.reshape(some_digit, (28,28))\n",
    "\n",
    "# Slice out only 18 pixels in the middle  \n",
    "some_digit = some_digit[5:23,5:23]\n",
    "\n",
    "# put them back as 1 array of len 324\n",
    "some_digit = np.reshape(some_digit, 324)\n",
    "\n",
    "print(some_digit.ndim)\n",
    "print(some_digit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf_18pixel_experiment.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok it kinda works. Let's try this on the whole train data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it on the actual train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "X_train_3d_real = []\n",
    "\n",
    "for i in range (len(X_train)): \n",
    "    one_digit = X_train[i]\n",
    "    one_digit = one_digit.reshape(28,28)\n",
    "    X_train_3d_real.append(one_digit)\n",
    "    \n",
    "print(len(X_train_3d_real))\n",
    "print(len(X_train_3d_real[4]))\n",
    "print(len(X_train_3d_real[4][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, exactly what I want \n",
    "\n",
    "Let's do some slicing. Since we still have a lot of 0s on the outside, let's slice more this time. Only takes 16 pixels in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(X_train_3d_real)): \n",
    "    X_train_3d_real[i] = X_train_3d_real[i][6:22,6:22]\n",
    "    \n",
    "print(len(X_train_3d_real))\n",
    "print(len(X_train_3d_real[0]))\n",
    "print(len(X_train_3d_real[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHould be 16:16\n",
      "SHould be 16:16\n",
      "2\n",
      "(16, 16)\n"
     ]
    }
   ],
   "source": [
    "one_digit = X_train_3d_real[i]\n",
    "print(\"SHould be 16:\" + str(len(one_digit)))\n",
    "print(\"SHould be 16:\" + str(len(one_digit[1])))\n",
    "\n",
    "omgiwanttosleep = np.array(one_digit)\n",
    "print(omgiwanttosleep.ndim)\n",
    "print(omgiwanttosleep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-123d7f2ad05c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0momgiwanttosleep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_digit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0momgiwanttosleep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momgiwanttosleep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mX_train_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0momgiwanttosleep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_final = np.array([])\n",
    "\n",
    "for i in range (len(X_train_3d_real)): \n",
    "    one_digit = X_train_3d_real[i]\n",
    "    omgiwanttosleep = np.array(one_digit)\n",
    "    omgiwanttosleep = np.reshape(omgiwanttosleep, 256)\n",
    "    X_train_final = np.concatenate((X_train_final,omgiwanttosleep))\n",
    "    \n",
    "    \n",
    "print(X_train_experiment_final.shape)\n",
    "print(X_train_experiment_final.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9949440,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final.shape)\n",
    "print(X_train_final.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this is not working. It was 10 minutes before I interupted the kernel so for the cell to finish, it's too expensive. It takes too long to stack each obs on each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_16pixel = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "with elapsed_timer() as sgd_timer:\n",
    "    sgd_clf_16pixel.fit(X_train_final, y_train)\n",
    "print(f\"sgd_clf.fit took {sgd_timer():.3f} secs to fit 60k obs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Things Up, pt. 1: importance values of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_2, y_train_2 = X[:60000], y[:60000]\n",
    "\n",
    "print(X_train_2.shape)\n",
    "print(y_train_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use random forest to measure the importance of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd_clf.fit took 59.130 secs to fit 60k obs\n",
      "pixel1 0.0\n",
      "pixel2 0.0\n",
      "pixel3 0.0\n",
      "pixel4 0.0\n",
      "pixel5 0.0\n",
      "pixel6 0.0\n",
      "pixel7 0.0\n",
      "pixel8 0.0\n",
      "pixel9 0.0\n",
      "pixel10 0.0\n",
      "pixel11 0.0\n",
      "pixel12 0.0\n",
      "pixel13 7.292368168820393e-08\n",
      "pixel14 2.6900974017708236e-07\n",
      "pixel15 2.8482488748219666e-07\n",
      "pixel16 7.272845049903546e-08\n",
      "pixel17 0.0\n",
      "pixel18 0.0\n",
      "pixel19 0.0\n",
      "pixel20 0.0\n",
      "pixel21 0.0\n",
      "pixel22 0.0\n",
      "pixel23 0.0\n",
      "pixel24 0.0\n",
      "pixel25 0.0\n",
      "pixel26 0.0\n",
      "pixel27 0.0\n",
      "pixel28 0.0\n",
      "pixel29 0.0\n",
      "pixel30 0.0\n",
      "pixel31 0.0\n",
      "pixel32 0.0\n",
      "pixel33 0.0\n",
      "pixel34 0.0\n",
      "pixel35 6.938858001962294e-07\n",
      "pixel36 1.7930511239868788e-06\n",
      "pixel37 1.1930973740222567e-06\n",
      "pixel38 1.5818930508303875e-06\n",
      "pixel39 6.840324761209703e-07\n",
      "pixel40 2.6159621977341806e-06\n",
      "pixel41 2.0410864192165205e-06\n",
      "pixel42 1.804472371249874e-06\n",
      "pixel43 3.6472157142120734e-06\n",
      "pixel44 3.814401004327182e-06\n",
      "pixel45 3.4474508064894157e-06\n",
      "pixel46 4.388782059067406e-06\n",
      "pixel47 1.2089922263523218e-06\n",
      "pixel48 1.2191609610072975e-06\n",
      "pixel49 1.4450403304741035e-06\n",
      "pixel50 8.811504098237376e-07\n",
      "pixel51 1.1373687544275605e-06\n",
      "pixel52 2.1575359130733276e-07\n",
      "pixel53 0.0\n",
      "pixel54 0.0\n",
      "pixel55 0.0\n",
      "pixel56 0.0\n",
      "pixel57 0.0\n",
      "pixel58 0.0\n",
      "pixel59 0.0\n",
      "pixel60 0.0\n",
      "pixel61 3.585658749748604e-07\n",
      "pixel62 1.2864939085608772e-07\n",
      "pixel63 2.6317930683727303e-06\n",
      "pixel64 1.255718126584932e-05\n",
      "pixel65 2.6224505275132164e-05\n",
      "pixel66 3.7755709118782764e-05\n",
      "pixel67 6.903622503817235e-05\n",
      "pixel68 0.00011459899470840813\n",
      "pixel69 0.0001552288721789104\n",
      "pixel70 0.00021261789471640425\n",
      "pixel71 0.00022087751785852835\n",
      "pixel72 0.00024010933094004424\n",
      "pixel73 0.00011136009135590189\n",
      "pixel74 9.129094106914941e-05\n",
      "pixel75 0.0001267987210378354\n",
      "pixel76 5.3259099135495216e-05\n",
      "pixel77 2.9963882191751807e-05\n",
      "pixel78 1.4021411406124366e-05\n",
      "pixel79 8.917519518685636e-06\n",
      "pixel80 2.5264107274368332e-06\n",
      "pixel81 2.1581889625737274e-07\n",
      "pixel82 1.457363010976013e-07\n",
      "pixel83 0.0\n",
      "pixel84 0.0\n",
      "pixel85 0.0\n",
      "pixel86 0.0\n",
      "pixel87 1.455308027508858e-07\n",
      "pixel88 2.7363254764079093e-07\n",
      "pixel89 5.599538689567555e-07\n",
      "pixel90 2.7624897815730677e-06\n",
      "pixel91 1.0035659456141056e-05\n",
      "pixel92 2.369539107753996e-05\n",
      "pixel93 6.697285029848922e-05\n",
      "pixel94 0.00011960974040452351\n",
      "pixel95 0.00021127718268319743\n",
      "pixel96 0.0005237903121249482\n",
      "pixel97 0.000696805658831352\n",
      "pixel98 0.0008651050247799605\n",
      "pixel99 0.0013236356905388916\n",
      "pixel100 0.001756118637193158\n",
      "pixel101 0.0023209608911531213\n",
      "pixel102 0.002117137466782485\n",
      "pixel103 0.0014198062336428486\n",
      "pixel104 0.0009039998446491567\n",
      "pixel105 0.0003774707148952941\n",
      "pixel106 0.00015024945932354969\n",
      "pixel107 6.402165690515229e-05\n",
      "pixel108 2.7571432487293314e-05\n",
      "pixel109 1.1585681824792745e-05\n",
      "pixel110 2.6775567441070707e-06\n",
      "pixel111 3.4166226781212166e-07\n",
      "pixel112 0.0\n",
      "pixel113 0.0\n",
      "pixel114 0.0\n",
      "pixel115 1.7326293373179388e-07\n",
      "pixel116 1.623814021249352e-06\n",
      "pixel117 3.780681797184827e-06\n",
      "pixel118 1.4655412758631778e-05\n",
      "pixel119 3.0923504169404354e-05\n",
      "pixel120 6.694541495500897e-05\n",
      "pixel121 0.00015808254455847916\n",
      "pixel122 0.0003806183474881852\n",
      "pixel123 0.0006538569923274052\n",
      "pixel124 0.0009673507761589199\n",
      "pixel125 0.0014593663304004257\n",
      "pixel126 0.0020111721534604595\n",
      "pixel127 0.0020508445128025604\n",
      "pixel128 0.0020210343616951705\n",
      "pixel129 0.0017314826247894406\n",
      "pixel130 0.0012446744239306173\n",
      "pixel131 0.0008446091187785551\n",
      "pixel132 0.0006002100887553121\n",
      "pixel133 0.00040020817233736057\n",
      "pixel134 0.00021900280306917387\n",
      "pixel135 0.0001438349579210977\n",
      "pixel136 8.408075509683538e-05\n",
      "pixel137 3.7873285787405895e-05\n",
      "pixel138 1.784687345560461e-05\n",
      "pixel139 1.8373587100294648e-06\n",
      "pixel140 4.4359255013355084e-07\n",
      "pixel141 0.0\n",
      "pixel142 0.0\n",
      "pixel143 3.7123098556739857e-07\n",
      "pixel144 3.9447691806468845e-06\n",
      "pixel145 1.4687029420283206e-05\n",
      "pixel146 4.744122175681681e-05\n",
      "pixel147 0.0001240651904293058\n",
      "pixel148 0.00022720001850874585\n",
      "pixel149 0.0005732588778863104\n",
      "pixel150 0.0011439513848118916\n",
      "pixel151 0.002207627884922666\n",
      "pixel152 0.002705069355921173\n",
      "pixel153 0.003641248007704852\n",
      "pixel154 0.004955274246910538\n",
      "pixel155 0.0052236525543208024\n",
      "pixel156 0.006335219723592295\n",
      "pixel157 0.00483571439539287\n",
      "pixel158 0.003236344695671703\n",
      "pixel159 0.0019639554091958208\n",
      "pixel160 0.0016214821634163467\n",
      "pixel161 0.0009931563802615775\n",
      "pixel162 0.000729159776708266\n",
      "pixel163 0.0005060134202384621\n",
      "pixel164 0.00036994980740429696\n",
      "pixel165 0.00011358373422008307\n",
      "pixel166 3.0083808307412143e-05\n",
      "pixel167 5.121549329601131e-06\n",
      "pixel168 1.1134270782459167e-06\n",
      "pixel169 0.0\n",
      "pixel170 2.0276138238149115e-07\n",
      "pixel171 4.035211232874777e-07\n",
      "pixel172 6.817159587131978e-06\n",
      "pixel173 3.1642922201005304e-05\n",
      "pixel174 9.92137487704302e-05\n",
      "pixel175 0.00022786950042911856\n",
      "pixel176 0.0005331008826689486\n",
      "pixel177 0.0011614010921454868\n",
      "pixel178 0.001974450974014559\n",
      "pixel179 0.002522293975245995\n",
      "pixel180 0.0027605753558014303\n",
      "pixel181 0.0024878740158300865\n",
      "pixel182 0.0030511895565739963\n",
      "pixel183 0.004032417937906644\n",
      "pixel184 0.004696883193456145\n",
      "pixel185 0.003948180772260537\n",
      "pixel186 0.0023695643798434516\n",
      "pixel187 0.0020027074341060205\n",
      "pixel188 0.0016315952726102124\n",
      "pixel189 0.0014313765169505243\n",
      "pixel190 0.001394182854238682\n",
      "pixel191 0.0012521665348403492\n",
      "pixel192 0.001026241525578307\n",
      "pixel193 0.0003821552799474097\n",
      "pixel194 6.451045106895148e-05\n",
      "pixel195 9.120367010869111e-06\n",
      "pixel196 1.9369416998974223e-06\n",
      "pixel197 0.0\n",
      "pixel198 6.16782763116416e-07\n",
      "pixel199 1.3799210977533768e-06\n",
      "pixel200 1.4430932040535477e-05\n",
      "pixel201 6.583462269636803e-05\n",
      "pixel202 0.00016004241361571508\n",
      "pixel203 0.00032418697878286386\n",
      "pixel204 0.0006228200664194053\n",
      "pixel205 0.0010369856497740903\n",
      "pixel206 0.0017963138996340807\n",
      "pixel207 0.002443632615278039\n",
      "pixel208 0.002317387147363067\n",
      "pixel209 0.002410958628368243\n",
      "pixel210 0.003650986620860399\n",
      "pixel211 0.005983427056018029\n",
      "pixel212 0.006207415750168825\n",
      "pixel213 0.004839874872928149\n",
      "pixel214 0.0033221546748045407\n",
      "pixel215 0.0025902021007202024\n",
      "pixel216 0.002322106351355616\n",
      "pixel217 0.0016793700308955196\n",
      "pixel218 0.0014725150660649816\n",
      "pixel219 0.001406474287073466\n",
      "pixel220 0.0013183758226837162\n",
      "pixel221 0.0007316905714950657\n",
      "pixel222 0.00016231343091703583\n",
      "pixel223 1.7040321699117506e-05\n",
      "pixel224 3.15867424537835e-06\n",
      "pixel225 6.646209353628979e-07\n",
      "pixel226 5.574667691389505e-07\n",
      "pixel227 3.713769995199673e-06\n",
      "pixel228 1.788969789701275e-05\n",
      "pixel229 9.046387254807948e-05\n",
      "pixel230 0.00019529907297952923\n",
      "pixel231 0.000379331899445566\n",
      "pixel232 0.0007431731478775452\n",
      "pixel233 0.0010867954734024201\n",
      "pixel234 0.00153375131409082\n",
      "pixel235 0.0028248728062363095\n",
      "pixel236 0.00313849355049995\n",
      "pixel237 0.0031592278069484552\n",
      "pixel238 0.004322553158546389\n",
      "pixel239 0.004943207082957741\n",
      "pixel240 0.005364792740250615\n",
      "pixel241 0.003930607250600173\n",
      "pixel242 0.00324929494119912\n",
      "pixel243 0.0030543196096681656\n",
      "pixel244 0.003212121296879568\n",
      "pixel245 0.002228214658267118\n",
      "pixel246 0.0014242532620291945\n",
      "pixel247 0.0012443992577755663\n",
      "pixel248 0.0011639330865338045\n",
      "pixel249 0.0007362901972661764\n",
      "pixel250 0.0001669198148432355\n",
      "pixel251 1.3707410854905889e-05\n",
      "pixel252 4.708665792379576e-07\n",
      "pixel253 0.0\n",
      "pixel254 3.192982840367788e-07\n",
      "pixel255 7.163885495298029e-06\n",
      "pixel256 2.525498943040299e-05\n",
      "pixel257 9.572212884235686e-05\n",
      "pixel258 0.0002116703959089238\n",
      "pixel259 0.0005366114956240484\n",
      "pixel260 0.0007030649376727705\n",
      "pixel261 0.001416315681410376\n",
      "pixel262 0.0023313890146852666\n",
      "pixel263 0.003650924362187562\n",
      "pixel264 0.0048425660732899735\n",
      "pixel265 0.0031597643136781475\n",
      "pixel266 0.0032632391116397272\n",
      "pixel267 0.003638722605480209\n",
      "pixel268 0.00422632681430093\n",
      "pixel269 0.0035078624894430885\n",
      "pixel270 0.003504312728349124\n",
      "pixel271 0.0039388576583312\n",
      "pixel272 0.003829526224228722\n",
      "pixel273 0.002541717032583441\n",
      "pixel274 0.0018275802946714774\n",
      "pixel275 0.0011056775418898108\n",
      "pixel276 0.0007789658330746565\n",
      "pixel277 0.0005016149884757046\n",
      "pixel278 0.0001329858367461995\n",
      "pixel279 2.19734208952676e-05\n",
      "pixel280 1.3525916986474147e-06\n",
      "pixel281 0.0\n",
      "pixel282 7.270461854497858e-07\n",
      "pixel283 5.665888299538692e-06\n",
      "pixel284 3.780497493494383e-05\n",
      "pixel285 0.00011454881715438482\n",
      "pixel286 0.00022460755879493923\n",
      "pixel287 0.0004114517590800441\n",
      "pixel288 0.0009537520167596463\n",
      "pixel289 0.0016415479058473578\n",
      "pixel290 0.0033818093871324025\n",
      "pixel291 0.005597388324690672\n",
      "pixel292 0.004696151888118984\n",
      "pixel293 0.0033101160072201447\n",
      "pixel294 0.0029140064478476004\n",
      "pixel295 0.0032390928739791\n",
      "pixel296 0.003509749331453524\n",
      "pixel297 0.003811588039878095\n",
      "pixel298 0.0038574319449914997\n",
      "pixel299 0.00414739055328773\n",
      "pixel300 0.003140718663143334\n",
      "pixel301 0.0026005577051983046\n",
      "pixel302 0.0019598345227257044\n",
      "pixel303 0.0011744475089522416\n",
      "pixel304 0.0004653878727116198\n",
      "pixel305 0.0002308948323126107\n",
      "pixel306 6.775830409777787e-05\n",
      "pixel307 1.1292570142064407e-05\n",
      "pixel308 1.3770792342874165e-06\n",
      "pixel309 0.0\n",
      "pixel310 1.0231474498317286e-06\n",
      "pixel311 4.104691219379678e-06\n",
      "pixel312 2.8632098836501435e-05\n",
      "pixel313 8.993936908260296e-05\n",
      "pixel314 0.00024401796354997512\n",
      "pixel315 0.0006512500414866259\n",
      "pixel316 0.001260216260183496\n",
      "pixel317 0.002252611918554031\n",
      "pixel318 0.00400077713022352\n",
      "pixel319 0.005356528240790898\n",
      "pixel320 0.005407592365989529\n",
      "pixel321 0.0036692765917380435\n",
      "pixel322 0.0030454647776665413\n",
      "pixel323 0.004324268466255992\n",
      "pixel324 0.004699289404289188\n",
      "pixel325 0.0031485191666051973\n",
      "pixel326 0.0035059672817369493\n",
      "pixel327 0.004563024930676416\n",
      "pixel328 0.003147808381332685\n",
      "pixel329 0.0023375696444826546\n",
      "pixel330 0.0022468921299112835\n",
      "pixel331 0.001750469102074977\n",
      "pixel332 0.0005989925857107022\n",
      "pixel333 0.00016665155213786776\n",
      "pixel334 3.6826965920706995e-05\n",
      "pixel335 1.0689059804081133e-05\n",
      "pixel336 1.6484563202085759e-06\n",
      "pixel337 0.0\n",
      "pixel338 8.588688867523734e-07\n",
      "pixel339 3.7950355538652698e-06\n",
      "pixel340 2.4436816419387896e-05\n",
      "pixel341 9.519690740174527e-05\n",
      "pixel342 0.0003063977834717874\n",
      "pixel343 0.0007954842701563499\n",
      "pixel344 0.0018148500655672827\n",
      "pixel345 0.0024564878884483147\n",
      "pixel346 0.004348304806246069\n",
      "pixel347 0.0054481566298280795\n",
      "pixel348 0.0061001406902292474\n",
      "pixel349 0.004797330047032542\n",
      "pixel350 0.004315086762088374\n",
      "pixel351 0.0091382758412393\n",
      "pixel352 0.004761289580196488\n",
      "pixel353 0.0035195385370239015\n",
      "pixel354 0.004018942851720049\n",
      "pixel355 0.004030509349963619\n",
      "pixel356 0.0024131539248419707\n",
      "pixel357 0.0016518718429712517\n",
      "pixel358 0.0021650992753957004\n",
      "pixel359 0.0021326107801042616\n",
      "pixel360 0.0007811684119950905\n",
      "pixel361 0.00010926018944924986\n",
      "pixel362 2.298946182237561e-05\n",
      "pixel363 8.65353161860217e-06\n",
      "pixel364 1.0882586341325112e-06\n",
      "pixel365 0.0\n",
      "pixel366 1.093745501008105e-07\n",
      "pixel367 1.4577035173508461e-06\n",
      "pixel368 1.7400366156266507e-05\n",
      "pixel369 9.084819215849221e-05\n",
      "pixel370 0.000390644879845981\n",
      "pixel371 0.0010299604284609624\n",
      "pixel372 0.001834858061503095\n",
      "pixel373 0.0031642722508032355\n",
      "pixel374 0.005316384049404927\n",
      "pixel375 0.0049252231809817386\n",
      "pixel376 0.006386498491493135\n",
      "pixel377 0.0050707521408964356\n",
      "pixel378 0.006535746556365352\n",
      "pixel379 0.009215924185371456\n",
      "pixel380 0.0039853482898411655\n",
      "pixel381 0.004324225872943645\n",
      "pixel382 0.00489060874664473\n",
      "pixel383 0.00389715875679331\n",
      "pixel384 0.0016883343021466886\n",
      "pixel385 0.0012959742395640846\n",
      "pixel386 0.001259025860151867\n",
      "pixel387 0.002294097184627136\n",
      "pixel388 0.0007324220537531798\n",
      "pixel389 0.00013504155888336528\n",
      "pixel390 2.475018135376675e-05\n",
      "pixel391 8.573696242750042e-06\n",
      "pixel392 7.401438637765545e-07\n",
      "pixel393 0.0\n",
      "pixel394 3.4347178988400437e-07\n",
      "pixel395 1.8130653612852865e-06\n",
      "pixel396 1.87641914666433e-05\n",
      "pixel397 9.85616118209722e-05\n",
      "pixel398 0.0004989217159559925\n",
      "pixel399 0.00114120907545525\n",
      "pixel400 0.0018744461544744477\n",
      "pixel401 0.004083833292563557\n",
      "pixel402 0.004514651717002497\n",
      "pixel403 0.005758769157581545\n",
      "pixel404 0.005299993195347563\n",
      "pixel405 0.004189205166663408\n",
      "pixel406 0.00837989556359485\n",
      "pixel407 0.007302567355428942\n",
      "pixel408 0.00432292264791342\n",
      "pixel409 0.00433262856030363\n",
      "pixel410 0.0073610827208426865\n",
      "pixel411 0.00342875915044233\n",
      "pixel412 0.0017266310109355656\n",
      "pixel413 0.001131945824946209\n",
      "pixel414 0.0014639284734627442\n",
      "pixel415 0.0016435445974703105\n",
      "pixel416 0.0006054751561835807\n",
      "pixel417 0.00017969110396421888\n",
      "pixel418 3.620353423235189e-05\n",
      "pixel419 1.1757034291280835e-05\n",
      "pixel420 6.033148867083665e-07\n",
      "pixel421 0.0\n",
      "pixel422 4.850919199903488e-07\n",
      "pixel423 3.058762851452996e-06\n",
      "pixel424 2.2355260168437377e-05\n",
      "pixel425 8.73769782330803e-05\n",
      "pixel426 0.00045008875442622886\n",
      "pixel427 0.0014455483068621462\n",
      "pixel428 0.0026347710538566042\n",
      "pixel429 0.004760067358867424\n",
      "pixel430 0.004182441624218226\n",
      "pixel431 0.004659118994758767\n",
      "pixel432 0.004891848036049795\n",
      "pixel433 0.004174945839027097\n",
      "pixel434 0.006442443973550284\n",
      "pixel435 0.006538409270695975\n",
      "pixel436 0.003416814560617869\n",
      "pixel437 0.004051753655709472\n",
      "pixel438 0.006694028886188654\n",
      "pixel439 0.0031624382347038766\n",
      "pixel440 0.0018127468093938038\n",
      "pixel441 0.0013987421654544734\n",
      "pixel442 0.0017533724559379165\n",
      "pixel443 0.0009677617013250626\n",
      "pixel444 0.0004401529025529509\n",
      "pixel445 0.000190506147147727\n",
      "pixel446 4.343475088631938e-05\n",
      "pixel447 1.3951495068717111e-05\n",
      "pixel448 7.359975340147097e-07\n",
      "pixel449 0.0\n",
      "pixel450 6.026129296611652e-07\n",
      "pixel451 3.7516188031339683e-06\n",
      "pixel452 2.9690996661566857e-05\n",
      "pixel453 8.834791568729351e-05\n",
      "pixel454 0.00044771858422996817\n",
      "pixel455 0.0014437322236419221\n",
      "pixel456 0.0036953522986991542\n",
      "pixel457 0.003663966612667757\n",
      "pixel458 0.004907071410715588\n",
      "pixel459 0.004657818253855778\n",
      "pixel460 0.004737766202530538\n",
      "pixel461 0.0053769932178450875\n",
      "pixel462 0.006821571393374206\n",
      "pixel463 0.006438454649414657\n",
      "pixel464 0.003058571023959392\n",
      "pixel465 0.003378580131479574\n",
      "pixel466 0.004068065396230026\n",
      "pixel467 0.0027965522629395567\n",
      "pixel468 0.0017091764710984753\n",
      "pixel469 0.001512721199417944\n",
      "pixel470 0.0015376862959258684\n",
      "pixel471 0.0009373060320795937\n",
      "pixel472 0.0004006641999425658\n",
      "pixel473 0.00018674037216887386\n",
      "pixel474 6.317846553622782e-05\n",
      "pixel475 1.5181128152903084e-05\n",
      "pixel476 2.170881880659041e-06\n",
      "pixel477 0.0\n",
      "pixel478 4.986322390016505e-07\n",
      "pixel479 6.325872616402271e-06\n",
      "pixel480 3.550721456281608e-05\n",
      "pixel481 0.00011528405951564533\n",
      "pixel482 0.000507925587467999\n",
      "pixel483 0.0010887175498353067\n",
      "pixel484 0.0026191080732430485\n",
      "pixel485 0.0034607881899097422\n",
      "pixel486 0.003977752777417194\n",
      "pixel487 0.004591844625880573\n",
      "pixel488 0.005946085522595192\n",
      "pixel489 0.005899781499785468\n",
      "pixel490 0.006921149803547907\n",
      "pixel491 0.003657247919429259\n",
      "pixel492 0.002664018561247161\n",
      "pixel493 0.0020347814072789383\n",
      "pixel494 0.00256402717390301\n",
      "pixel495 0.0021874388077689315\n",
      "pixel496 0.0017859440982807857\n",
      "pixel497 0.0014135276937835958\n",
      "pixel498 0.0008149879359984116\n",
      "pixel499 0.0006513079090014455\n",
      "pixel500 0.00035743374760346784\n",
      "pixel501 0.00020723868972134834\n",
      "pixel502 6.237780246017885e-05\n",
      "pixel503 1.3258946099900631e-05\n",
      "pixel504 2.9778373587523646e-06\n",
      "pixel505 6.654994880051383e-08\n",
      "pixel506 1.3937686003960156e-07\n",
      "pixel507 8.09417651304755e-06\n",
      "pixel508 5.144941887802063e-05\n",
      "pixel509 0.00019080324893512777\n",
      "pixel510 0.0005768493858841532\n",
      "pixel511 0.0012558305127569438\n",
      "pixel512 0.0022943516625241796\n",
      "pixel513 0.0028044800412921206\n",
      "pixel514 0.004107366758657614\n",
      "pixel515 0.006364430321747475\n",
      "pixel516 0.006551341893477899\n",
      "pixel517 0.00447110401231901\n",
      "pixel518 0.004286272393094058\n",
      "pixel519 0.0027833711317672137\n",
      "pixel520 0.0018196145269939214\n",
      "pixel521 0.0012975116963975092\n",
      "pixel522 0.001885385312979145\n",
      "pixel523 0.0023354804153468095\n",
      "pixel524 0.0023142097539670787\n",
      "pixel525 0.0015730843670383541\n",
      "pixel526 0.001075542887081911\n",
      "pixel527 0.0006487427571078005\n",
      "pixel528 0.0004579995094783244\n",
      "pixel529 0.0002327080367014211\n",
      "pixel530 6.0040606408044006e-05\n",
      "pixel531 5.56035914376281e-06\n",
      "pixel532 7.265134797329236e-07\n",
      "pixel533 0.0\n",
      "pixel534 9.234028564892213e-07\n",
      "pixel535 7.891728195330825e-06\n",
      "pixel536 6.620016997530902e-05\n",
      "pixel537 0.00020870355639285052\n",
      "pixel538 0.0006256078618159561\n",
      "pixel539 0.0016762362400251974\n",
      "pixel540 0.003183863754400877\n",
      "pixel541 0.0037529916057839237\n",
      "pixel542 0.004253631441541017\n",
      "pixel543 0.006348703990554971\n",
      "pixel544 0.005526892468892113\n",
      "pixel545 0.00360899726931546\n",
      "pixel546 0.002620376363641668\n",
      "pixel547 0.0018820609585911122\n",
      "pixel548 0.0013120266572343722\n",
      "pixel549 0.0013197602181246478\n",
      "pixel550 0.001962682378888329\n",
      "pixel551 0.003515727178227419\n",
      "pixel552 0.00287169516258918\n",
      "pixel553 0.0012788332913593636\n",
      "pixel554 0.0010831633486318552\n",
      "pixel555 0.0006659015063998401\n",
      "pixel556 0.00041606849730243953\n",
      "pixel557 0.00020315242267505878\n",
      "pixel558 2.77373308560253e-05\n",
      "pixel559 4.792724590883817e-06\n",
      "pixel560 3.942739293662425e-07\n",
      "pixel561 0.0\n",
      "pixel562 4.71666427146262e-07\n",
      "pixel563 6.527331662691595e-06\n",
      "pixel564 6.598001463252901e-05\n",
      "pixel565 0.0002113216948983628\n",
      "pixel566 0.000624638571369519\n",
      "pixel567 0.0016149554969340854\n",
      "pixel568 0.0041550181915153955\n",
      "pixel569 0.00498090246196133\n",
      "pixel570 0.005167727176599842\n",
      "pixel571 0.005202338085967941\n",
      "pixel572 0.0034745304209713944\n",
      "pixel573 0.0028940556659588436\n",
      "pixel574 0.0022593569929994727\n",
      "pixel575 0.001794406846835232\n",
      "pixel576 0.0015933304297191316\n",
      "pixel577 0.0013551636916115776\n",
      "pixel578 0.0023626825463255244\n",
      "pixel579 0.0023682752218753635\n",
      "pixel580 0.0017216530707388383\n",
      "pixel581 0.001263813224658239\n",
      "pixel582 0.0008781312173322626\n",
      "pixel583 0.000569974996414689\n",
      "pixel584 0.00030458473355649083\n",
      "pixel585 0.00011292550586957234\n",
      "pixel586 1.6714084343934428e-05\n",
      "pixel587 3.522172852901907e-06\n",
      "pixel588 5.971048368254937e-08\n",
      "pixel589 0.0\n",
      "pixel590 7.229849090643855e-08\n",
      "pixel591 5.463199985282564e-06\n",
      "pixel592 4.384545243898328e-05\n",
      "pixel593 0.00018363842736379257\n",
      "pixel594 0.0004968181794422772\n",
      "pixel595 0.0012288637864525948\n",
      "pixel596 0.0030266162012521336\n",
      "pixel597 0.005270226726342153\n",
      "pixel598 0.004076379230598928\n",
      "pixel599 0.002810018409651631\n",
      "pixel600 0.0017932017620922803\n",
      "pixel601 0.00154970991211824\n",
      "pixel602 0.0015637430796800757\n",
      "pixel603 0.0013174181274235803\n",
      "pixel604 0.0012078582285791081\n",
      "pixel605 0.001150707401389859\n",
      "pixel606 0.0014863399602850394\n",
      "pixel607 0.0013873469484691273\n",
      "pixel608 0.0012509942174697738\n",
      "pixel609 0.0009933041804457703\n",
      "pixel610 0.0006226690782592598\n",
      "pixel611 0.0003962902171153647\n",
      "pixel612 0.000152328483014877\n",
      "pixel613 5.8760751683747256e-05\n",
      "pixel614 1.0850824954907686e-05\n",
      "pixel615 2.4610620717272546e-06\n",
      "pixel616 0.0\n",
      "pixel617 0.0\n",
      "pixel618 0.0\n",
      "pixel619 3.7039703652456993e-06\n",
      "pixel620 2.4483725587869216e-05\n",
      "pixel621 0.00010064534568974088\n",
      "pixel622 0.0002825997016201125\n",
      "pixel623 0.0007195554102571779\n",
      "pixel624 0.0015231496865379577\n",
      "pixel625 0.0028602735228035092\n",
      "pixel626 0.003444581905009502\n",
      "pixel627 0.0028498074800512537\n",
      "pixel628 0.0021374230883915227\n",
      "pixel629 0.0017619350132088102\n",
      "pixel630 0.001663991181456668\n",
      "pixel631 0.001663351902941138\n",
      "pixel632 0.0015431914674884802\n",
      "pixel633 0.0013462010399607255\n",
      "pixel634 0.0010385349153760233\n",
      "pixel635 0.0008223551375652354\n",
      "pixel636 0.0006944006242946364\n",
      "pixel637 0.00047897408092395077\n",
      "pixel638 0.00032594018774331426\n",
      "pixel639 0.00015864709219186047\n",
      "pixel640 6.434374401354412e-05\n",
      "pixel641 2.371528227407238e-05\n",
      "pixel642 6.785098510304552e-06\n",
      "pixel643 1.3841190862858978e-06\n",
      "pixel644 0.0\n",
      "pixel645 0.0\n",
      "pixel646 0.0\n",
      "pixel647 1.1004845556527482e-06\n",
      "pixel648 1.4810450283604833e-05\n",
      "pixel649 6.961218682428e-05\n",
      "pixel650 0.0001364279790519772\n",
      "pixel651 0.00036547553389447733\n",
      "pixel652 0.0007394093373958387\n",
      "pixel653 0.00148158932848679\n",
      "pixel654 0.0019635698643655076\n",
      "pixel655 0.0027162698204065295\n",
      "pixel656 0.0037689483928180934\n",
      "pixel657 0.004856423413712207\n",
      "pixel658 0.0047897404084052886\n",
      "pixel659 0.0034304277275803564\n",
      "pixel660 0.0024454839922338203\n",
      "pixel661 0.0016375172718803464\n",
      "pixel662 0.0009956818847549338\n",
      "pixel663 0.0006632227009412777\n",
      "pixel664 0.00043849328108021973\n",
      "pixel665 0.0002586229168257018\n",
      "pixel666 0.00014297157388793103\n",
      "pixel667 7.370058345184007e-05\n",
      "pixel668 3.4162411699012165e-05\n",
      "pixel669 1.0996689292621268e-05\n",
      "pixel670 4.897981503206182e-06\n",
      "pixel671 1.0028637464788622e-06\n",
      "pixel672 0.0\n",
      "pixel673 0.0\n",
      "pixel674 0.0\n",
      "pixel675 1.7193581543474244e-06\n",
      "pixel676 1.4008267498999826e-05\n",
      "pixel677 3.7312904930160494e-05\n",
      "pixel678 0.00011343680523043016\n",
      "pixel679 0.0002401403066892804\n",
      "pixel680 0.00040035694781496116\n",
      "pixel681 0.0007517941447749033\n",
      "pixel682 0.0008664516054611258\n",
      "pixel683 0.001275243587232347\n",
      "pixel684 0.001415777881221919\n",
      "pixel685 0.0015886108508053485\n",
      "pixel686 0.001393492371953934\n",
      "pixel687 0.0011074973283979846\n",
      "pixel688 0.0008056792512882028\n",
      "pixel689 0.0005383502181719755\n",
      "pixel690 0.00041813935602662316\n",
      "pixel691 0.0003112174192143569\n",
      "pixel692 0.00024497039979398715\n",
      "pixel693 0.00014847649849293175\n",
      "pixel694 8.882407674782992e-05\n",
      "pixel695 3.8387574451625276e-05\n",
      "pixel696 1.9563506806790977e-05\n",
      "pixel697 6.060770183152351e-06\n",
      "pixel698 1.8508788745330012e-06\n",
      "pixel699 5.570571909982191e-07\n",
      "pixel700 0.0\n",
      "pixel701 0.0\n",
      "pixel702 0.0\n",
      "pixel703 0.0\n",
      "pixel704 2.0463144923157276e-06\n",
      "pixel705 1.4768857488651545e-05\n",
      "pixel706 5.853104682935397e-05\n",
      "pixel707 0.00010297157334288085\n",
      "pixel708 0.0003037575739330347\n",
      "pixel709 0.0004798844134909178\n",
      "pixel710 0.0006715829605218503\n",
      "pixel711 0.000898148770090717\n",
      "pixel712 0.0010056912902357208\n",
      "pixel713 0.0012559811558981555\n",
      "pixel714 0.0009152381495349977\n",
      "pixel715 0.0004980739713026192\n",
      "pixel716 0.00044987371604340187\n",
      "pixel717 0.0005022419979242701\n",
      "pixel718 0.0005377183178137988\n",
      "pixel719 0.0002867701866163694\n",
      "pixel720 0.00017842063766506118\n",
      "pixel721 0.00010679820626343507\n",
      "pixel722 4.020546077012743e-05\n",
      "pixel723 1.6959489406447736e-05\n",
      "pixel724 6.632551805867443e-06\n",
      "pixel725 1.752372976614059e-06\n",
      "pixel726 1.2139413487772732e-07\n",
      "pixel727 2.592247592602298e-07\n",
      "pixel728 0.0\n",
      "pixel729 0.0\n",
      "pixel730 0.0\n",
      "pixel731 0.0\n",
      "pixel732 1.48189859691495e-07\n",
      "pixel733 5.00679616268567e-06\n",
      "pixel734 8.13042885189286e-06\n",
      "pixel735 1.4942634341736889e-05\n",
      "pixel736 3.7568942992501e-05\n",
      "pixel737 7.312704458637373e-05\n",
      "pixel738 9.661608900540172e-05\n",
      "pixel739 0.00011337717336620989\n",
      "pixel740 0.00018931201432182828\n",
      "pixel741 0.00020480767362265813\n",
      "pixel742 0.00023696852277313733\n",
      "pixel743 0.00020161574273731082\n",
      "pixel744 0.00024058284742283281\n",
      "pixel745 0.00016820198826852304\n",
      "pixel746 0.00011561719115807304\n",
      "pixel747 6.763182519649641e-05\n",
      "pixel748 3.5477160019509354e-05\n",
      "pixel749 2.5276084586532436e-05\n",
      "pixel750 1.0119788848947853e-05\n",
      "pixel751 3.21609538304403e-06\n",
      "pixel752 1.2478342554694564e-06\n",
      "pixel753 2.7299804676784307e-07\n",
      "pixel754 0.0\n",
      "pixel755 0.0\n",
      "pixel756 0.0\n",
      "pixel757 0.0\n",
      "pixel758 0.0\n",
      "pixel759 0.0\n",
      "pixel760 0.0\n",
      "pixel761 0.0\n",
      "pixel762 0.0\n",
      "pixel763 2.7988779070821667e-07\n",
      "pixel764 2.958700747226247e-07\n",
      "pixel765 1.6875865418176874e-06\n",
      "pixel766 1.3976379452188734e-06\n",
      "pixel767 1.811949478167927e-06\n",
      "pixel768 3.588244026146326e-06\n",
      "pixel769 3.3552663291520767e-06\n",
      "pixel770 3.3461088293360592e-06\n",
      "pixel771 5.957093649234325e-06\n",
      "pixel772 5.646459277171986e-06\n",
      "pixel773 3.5280974010561866e-06\n",
      "pixel774 4.383327258856083e-06\n",
      "pixel775 1.6979850674747425e-06\n",
      "pixel776 1.4426571256960237e-06\n",
      "pixel777 2.2416981770608366e-06\n",
      "pixel778 1.587632941130723e-06\n",
      "pixel779 5.189833848106887e-07\n",
      "pixel780 1.5657982132272345e-07\n",
      "pixel781 0.0\n",
      "pixel782 0.0\n",
      "pixel783 0.0\n",
      "pixel784 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs=-1)\n",
    "\n",
    "with elapsed_timer() as rndclf_timer:\n",
    "    rnd_clf.fit(X_train_2, y_train_2)\n",
    "print(f\"rnd_clf.fit took {rndclf_timer():.3f} secs to fit 60k obs\")\n",
    "\n",
    "\n",
    "for name, score in zip(mnist[\"feature_names\"], rnd_clf.feature_importances_):       \n",
    "    print(name, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure mnist_feature_importance_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some code from the book \n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'])\n",
    "\n",
    "save_fig(\"mnist_feature_importance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so looks like the importance really starts to increase from line 4,5ish, which mean we should look at pixels from around ~130-150. Let try some different threseholds to see which one works the best. We expect to see around 256 pixels pull through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold of 0.001, we will keep 301 features\n",
      "Threshold of 0.002 ,we will keep 196 features\n",
      "Threshold of 0.003, we will keep 141 features\n"
     ]
    }
   ],
   "source": [
    "a = np.array(mnist[\"feature_names\"])\n",
    "b = rnd_clf.feature_importances_\n",
    "\n",
    "threshold_point001 = a[(b > 0.001)]\n",
    "threshold_point002 = a[(b > 0.002)]\n",
    "threshold_point003 = a[(b > 0.003)]\n",
    "\n",
    "print(\"Threshold of 0.001, we will keep \" + str(len(threshold_point001)) + \" features\")\n",
    "print(\"Threshold of 0.002 ,we will keep \" + str(len(threshold_point002)) + \" features\")\n",
    "print(\"Threshold of 0.003, we will keep \" + str(len(threshold_point003)) + \" features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's go with 0.002 then. 200 features seem sufficient enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhv\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,784) into shape (784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2721672d54cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mone_digit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mone_digit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_digit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreshold_point002\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_digit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (0,784) into shape (784)"
     ]
    }
   ],
   "source": [
    "for i in range (len(X_train_2)):\n",
    "    one_digit = X_train_2[i]\n",
    "    one_digit = one_digit[b in threshold_point002]\n",
    "    X_train_2[i] = one_digit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of the boolean_pixels array is: 784\n"
     ]
    }
   ],
   "source": [
    "boolean_pixels = []\n",
    "\n",
    "for i in range (len(a)):\n",
    "    if a[i] in threshold_point002:\n",
    "        boolean_pixels.append(True)\n",
    "    else:\n",
    "        boolean_pixels.append(False)\n",
    "\n",
    "boolean_pixels = np.array(boolean_pixels)\n",
    "\n",
    "print(\"Len of the boolean_pixels array is: \" + str(len(boolean_pixels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through one by one digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (196) into shape (784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a64150aaa282>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mone_digit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mone_digit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_digit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboolean_pixels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_digit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_train_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (196) into shape (784)"
     ]
    }
   ],
   "source": [
    "X_train_2_final = np.array\n",
    "\n",
    "for i in range (len(X_train_2)):\n",
    "    one_digit = X_train_2[i]\n",
    "    one_digit = one_digit[boolean_pixels]\n",
    "    X_train_2[i] = one_digit\n",
    "    \n",
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we want a 2-d array shape of (60,000, 196). So let's initialize that array first, and then fill it with filtered pixels from X_train_2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  96, 244,   0,   0,   0,   0,\n",
       "         0,   0,   0, 127, 251, 251,   0,   0,   0,   0,   0,   0,  68,\n",
       "       236, 251, 211,  31,   0,   0,   0,   0,   0,   0,  60, 228, 251,\n",
       "       251,  94,   0,   0,   0,   0,   0,   0,   0, 155, 253, 253, 189,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  20, 253, 251, 235,  66,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  32, 205, 253, 251, 126,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 251, 253, 184,\n",
       "        15,   0,   0,   0,   0,   0,   0,  80, 240, 251, 193,  23,   0,\n",
       "         0,   0,   0,   0,   0,  32, 253, 253, 253, 159,   0,   0,   0,\n",
       "         0,   0,   0,   0, 151, 251, 251, 251,  39,   0,   0,   0,   0,\n",
       "         0,   0,  48, 221, 251, 251, 172,   0,   0,   0,   0,   0,   0,\n",
       "         0, 234, 251, 251, 196,  12,   0,   0,   0,   0,   0, 253, 251,\n",
       "       251,  89,   0,   0,   0,   0, 159, 255, 253, 253,  31,   0,   0,\n",
       "         0,  48, 228, 253,  64, 251, 253, 220, 253, 220,   0,   0,   0,\n",
       "         0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2_final = np.arange(60000*196).reshape(60000,196)\n",
    "\n",
    "for i in range (len(X_train_2)):\n",
    "    one_digit = X_train_2[i]\n",
    "    one_digit = one_digit[boolean_pixels]\n",
    "    X_train_2_final[i] = one_digit\n",
    "    \n",
    "X_train_2_final[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 196)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alrighty, we are finally ready for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_clf.fit took 50.892 secs to fit 60k obs, each with only 196 features\n"
     ]
    }
   ],
   "source": [
    "sgd_clf_feature_importance = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "with elapsed_timer() as sgd_timer:\n",
    "    sgd_clf_feature_importance.fit(X_train_2_final, y_train)\n",
    "print(f\"sgd_clf.fit took {sgd_timer():.3f} secs to fit 60k obs, each with only 196 features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above it takes 142s to fit a sgd classifier into the whole train dataset, which consists 784 features each observation.**\n",
    "\n",
    "**By reducing the number of features down to 196, it now only takes 50s.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a confusion matrix for multiclass classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](datasets/Lab4/Multi_Class_Classification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 196)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_196_pixels = np.arange(10000*196).reshape(10000,196)\n",
    "\n",
    "for i in range (len(X_test)):\n",
    "    one_digit = X_test[i]\n",
    "    one_digit = one_digit[boolean_pixels]\n",
    "    X_test_196_pixels[i] = one_digit\n",
    "    \n",
    "X_test_196_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_feature_importance_pred = sgd_clf_feature_importance.predict(X_test_196_pixels)\n",
    "\n",
    "y_test_feature_importance_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1008]\n",
      " [   1 1113]\n",
      " [   2  783]\n",
      " [   3  473]\n",
      " [   4  798]\n",
      " [   5 1373]\n",
      " [   6 1133]\n",
      " [   7  591]\n",
      " [   8  932]\n",
      " [   9 1796]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_test_feature_importance_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so there are 10 distinct classes (0 to 9). We will want to have a 2d array of shape 10x10 for the confusion matrix. \n",
    "\n",
    "Go into the y_test array, check each digit to get the index to see the number we predict in y_test_feature_importance_pred\n",
    "\n",
    "(We can also do this with 10 different OneVsRest Classifier to compute Precision and Recall for 10 digits, but let's do it this way this time so we will learn something new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 913,    0,    1,    0,    0,   25,   24,    0,    4,   13],\n",
       "       [   0, 1072,    2,    0,    3,    5,    6,    1,   45,    1],\n",
       "       [  13,    9,  743,   11,   23,   31,   47,    1,   96,   58],\n",
       "       [  21,    4,   15,  454,    5,  368,   17,    3,   54,   69],\n",
       "       [   2,    1,    1,    1,  705,    9,   42,    0,    8,  213],\n",
       "       [  17,    3,    3,    1,    8,  758,   48,    1,   15,   38],\n",
       "       [  22,    2,    5,    0,    9,    9,  902,    0,    6,    3],\n",
       "       [   5,   11,    9,    1,   20,   10,    4,  582,   32,  354],\n",
       "       [   9,    5,    4,    5,   13,  135,   39,    1,  668,   95],\n",
       "       [   6,    6,    0,    0,   12,   23,    4,    2,    4,  952]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((10,10))\n",
    "\n",
    "for i in range (len(y_test)):\n",
    "    confusion_matrix[y_test[i]][y_test_feature_importance_pred[i]] += 1\n",
    "    \n",
    "confusion_matrix = confusion_matrix.astype(int)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wowla perfect. Let's compute some numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have pretty even numbers of 10 digits, accuracy can be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RandomForrestClassifier to measure the importance of features, we get the accuracy of: 0.7749\n"
     ]
    }
   ],
   "source": [
    "FI_accuracy = 0\n",
    "\n",
    "for i in range (len(confusion_matrix)):\n",
    "    FI_accuracy += confusion_matrix[i][i]\n",
    "\n",
    "FI_accuracy /= 10000\n",
    "\n",
    "print(\"Using RandomForrestClassifier to measure the importance of features, we get the accuracy of: \" + str(FI_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision: the accuracy of the positive predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 41, 40, 19, 93, 615, 231, 9, 264, 844]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP = [0] * 10  \n",
    "\n",
    "for i in range (len(FP)):\n",
    "    for j in range (len(FP)):\n",
    "        if i != j:\n",
    "            FP[i] += confusion_matrix[j][i]\n",
    "\n",
    "FP  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[913, 1072, 743, 454, 705, 758, 902, 582, 668, 952]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = [0] * 10  \n",
    "\n",
    "for i in range (len(FP)):\n",
    "    TP[i] += confusion_matrix[i][i]\n",
    "\n",
    "TP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Precision: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9057539682539683,\n",
       " 0.963162623539982,\n",
       " 0.9489144316730523,\n",
       " 0.959830866807611,\n",
       " 0.8834586466165414,\n",
       " 0.5520757465404225,\n",
       " 0.7961165048543689,\n",
       " 0.9847715736040609,\n",
       " 0.7167381974248928,\n",
       " 0.5300668151447662]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = [0] * 10\n",
    "\n",
    "for i in range (len(precision)):\n",
    "    precision[i] = TP[i] / (TP[i] + FP[i])\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok there we have it the precision of each digit (not doing so great with digit 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall: this is the ratio of positive instances that are correctly detected by the classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 63, 289, 556, 277, 134, 56, 446, 306, 57]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN = [0] * 10\n",
    "\n",
    "for i in range (len(FP)):\n",
    "    for j in range (len(FP)):\n",
    "        if i != j:\n",
    "            FN[i] += confusion_matrix[i][j]\n",
    "\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9316326530612244,\n",
       " 0.9444933920704845,\n",
       " 0.7199612403100775,\n",
       " 0.4495049504950495,\n",
       " 0.7179226069246436,\n",
       " 0.8497757847533632,\n",
       " 0.941544885177453,\n",
       " 0.566147859922179,\n",
       " 0.6858316221765913,\n",
       " 0.9435084241823588]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = [0] * 10\n",
    "\n",
    "for i in range (len(recall)):\n",
    "    recall[i] = TP[i] / (TP[i] + FN[i])\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the trade off between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Things Up, pt. 2\n",
    "\n",
    "Use PCA to reduce the dimensionality of the space. Directly compare this approach with your results in part 1 by choosing a reduced input space of the same size you experimented with there. Then also try the reduction that preserves just more than 80% of the variance and see how that performs in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So above we decide to keep 196 pixels of our training dataset. Let's start off by directly choosing 196 as the number of components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca.fit_transform took 5.560 secs to fit transform 60k obs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_196 = PCA(n_components = 196)\n",
    "\n",
    "with elapsed_timer() as pca196_timer:\n",
    "    X_train_pca_reduced_196 = pca_196.fit_transform(X_train)\n",
    "print(f\"pca.fit_transform took {pca196_timer():.3f} secs to fit transform 60k obs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 196)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_reduced_196.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09704664 0.07095924 0.06169089 0.05389419 0.04868797 0.04312231\n",
      " 0.0327193  0.02883895 0.02762029 0.02357001 0.0210919  0.02022991\n",
      " 0.01715818 0.01692111 0.01578641 0.01482953 0.01324561 0.01276897\n",
      " 0.01187263 0.01152684 0.01066166 0.01006713 0.00953573 0.00912544\n",
      " 0.00883405 0.00839319 0.00812579 0.00786366 0.00744733 0.00690859\n",
      " 0.00658094 0.00648148 0.00602615 0.00586582 0.00570021 0.00543628\n",
      " 0.00505786 0.00487859 0.00481429 0.00472266 0.00456747 0.00444836\n",
      " 0.00418501 0.00398215 0.00384975 0.00375103 0.00362009 0.00351591\n",
      " 0.00340058 0.00321874 0.00319017 0.00312805 0.00295983 0.00288955\n",
      " 0.0028413  0.00271436 0.00269521 0.00258473 0.00253771 0.00244781\n",
      " 0.00240506 0.00239263 0.00230408 0.00221532 0.00213721 0.00207225\n",
      " 0.00203043 0.00196783 0.00192853 0.00188632 0.00186977 0.00181083\n",
      " 0.00177562 0.00174898 0.00165758 0.00163894 0.00161462 0.00155116\n",
      " 0.00147613 0.00143176 0.00142094 0.00141153 0.00140174 0.00135736\n",
      " 0.00133847 0.00132396 0.00130157 0.00125873 0.00122828 0.00121584\n",
      " 0.00117034 0.00114873 0.00113244 0.00110885 0.00109001 0.00106923\n",
      " 0.00104195 0.00104007 0.00101256 0.00100527 0.00098401 0.00094968\n",
      " 0.00094133 0.00091615 0.00090784 0.00089686 0.00086537 0.00085514\n",
      " 0.00084561 0.00082247 0.00079155 0.00078589 0.00078454 0.00076876\n",
      " 0.00076397 0.00075304 0.00073675 0.00072705 0.00071954 0.00070674\n",
      " 0.0006953  0.00069208 0.00068323 0.00067396 0.00066678 0.00064508\n",
      " 0.00063548 0.00063149 0.00062282 0.0006051  0.00060319 0.0005943\n",
      " 0.00058802 0.00058624 0.00058097 0.00057641 0.00056507 0.0005543\n",
      " 0.00053439 0.00052533 0.00052391 0.00050914 0.00050226 0.00050034\n",
      " 0.00049762 0.00048968 0.00048451 0.00048145 0.00047211 0.00046713\n",
      " 0.000464   0.00046164 0.00045821 0.0004494  0.00044777 0.00044115\n",
      " 0.000434   0.00042458 0.0004218  0.00041936 0.00041377 0.00040481\n",
      " 0.00039799 0.00039425 0.00039214 0.00038466 0.00038262 0.00037621\n",
      " 0.00037325 0.00036859 0.00036384 0.00035975 0.00035839 0.00035597\n",
      " 0.0003465  0.00034475 0.00034199 0.00034075 0.00033218 0.00033093\n",
      " 0.00032364 0.00032296 0.00031754 0.00031441 0.0003103  0.0003095\n",
      " 0.00030607 0.0003024  0.00029895 0.00029446 0.00029025 0.00028782\n",
      " 0.00028547 0.00028226 0.0002756  0.00027406]\n"
     ]
    }
   ],
   "source": [
    "print(pca_196.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_clf_pca196.fit took 33.137 secs to fit 60k obs, each with only 196 features\n"
     ]
    }
   ],
   "source": [
    "sgd_clf_pca196 = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "with elapsed_timer() as sgd_pca196_timer:\n",
    "    sgd_clf_pca196.fit(X_train_pca_reduced_196, y_train)\n",
    "print(f\"sgd_clf_pca196.fit took {sgd_pca196_timer():.3f} secs to fit 60k obs, each with only 196 features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 196)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_reduced_196 = pca_196.transform(X_test)\n",
    "X_test_pca_reduced_196.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pca196_pred = sgd_clf_pca196.predict(X_test_pca_reduced_196)\n",
    "\n",
    "y_test_pca196_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for PCA196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 946,    0,    6,    1,    0,    7,   13,    4,    1,    2],\n",
       "       [   0, 1087,    6,    7,    0,   10,    7,    2,   15,    1],\n",
       "       [   6,    9,  935,   13,    3,    0,   17,   25,   21,    3],\n",
       "       [   2,    0,   26,  919,    1,   18,    8,   10,   15,   11],\n",
       "       [   1,    0,    7,    0,  870,    2,   16,   15,   10,   61],\n",
       "       [   8,    1,    9,   49,   12,  726,   31,   13,   27,   16],\n",
       "       [   8,    1,   11,    0,    6,   19,  909,    0,    4,    0],\n",
       "       [   3,    9,   17,    6,    5,    3,    1,  944,    0,   40],\n",
       "       [   8,    6,   21,   21,    7,   25,   31,   25,  811,   19],\n",
       "       [   7,    5,    3,   12,   37,    6,    0,   41,   15,  883]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_pca196 = np.zeros((10,10))\n",
    "\n",
    "for i in range (len(y_test)):\n",
    "    confusion_matrix_pca196[y_test[i]][y_test_pca196_pred[i]] += 1\n",
    "    \n",
    "confusion_matrix_pca196 = confusion_matrix_pca196.astype(int)\n",
    "confusion_matrix_pca196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PCA to reduce the dimension down to 196, we get the accuracy of: 0.903\n"
     ]
    }
   ],
   "source": [
    "pca196_accuracy = 0\n",
    "\n",
    "for i in range (len(confusion_matrix_pca196)):\n",
    "    pca196_accuracy += confusion_matrix_pca196[i][i]\n",
    "\n",
    "pca196_accuracy /= 10000\n",
    "\n",
    "print(\"Using PCA to reduce the dimension down to 196, we get the accuracy of: \" + str(pca196_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow impressive. We get much higher accuracy. Let's check precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[946, 1087, 935, 919, 870, 726, 909, 944, 811, 883]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_pca196 = [0] * 10  \n",
    "\n",
    "for i in range (len(TP_pca196)):\n",
    "    TP_pca196[i] += confusion_matrix_pca196[i][i]\n",
    "\n",
    "TP_pca196 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 31, 106, 109, 71, 90, 124, 135, 108, 153]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_pca196 = [0] * 10  \n",
    "\n",
    "for i in range (len(FP_pca196)):\n",
    "    for j in range (len(FP_pca196)):\n",
    "        if i != j:\n",
    "            FP_pca196[i] += confusion_matrix_pca196[j][i]\n",
    "\n",
    "FP_pca196  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9565217391304348,\n",
       " 0.9722719141323792,\n",
       " 0.8981748318924111,\n",
       " 0.8939688715953308,\n",
       " 0.924548352816153,\n",
       " 0.8897058823529411,\n",
       " 0.8799612778315585,\n",
       " 0.8748841519925857,\n",
       " 0.8824809575625681,\n",
       " 0.8523166023166023]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_pca196 = [0] * 10\n",
    "\n",
    "for i in range (len(precision_pca196)):\n",
    "    precision_pca196[i] = TP_pca196[i] / (TP_pca196[i] + FP_pca196[i])\n",
    "\n",
    "precision_pca196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForrest</th>\n",
       "      <th>PCA196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905754</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963163</td>\n",
       "      <td>0.972272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.948914</td>\n",
       "      <td>0.898175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959831</td>\n",
       "      <td>0.893969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.924548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.552076</td>\n",
       "      <td>0.889706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.879961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984772</td>\n",
       "      <td>0.874884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.882481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.530067</td>\n",
       "      <td>0.852317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForrest    PCA196\n",
       "0       0.905754  0.956522\n",
       "1       0.963163  0.972272\n",
       "2       0.948914  0.898175\n",
       "3       0.959831  0.893969\n",
       "4       0.883459  0.924548\n",
       "5       0.552076  0.889706\n",
       "6       0.796117  0.879961\n",
       "7       0.984772  0.874884\n",
       "8       0.716738  0.882481\n",
       "9       0.530067  0.852317"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d_precision_pcaVSrdnforrest = {'RandomForrest': precision, 'PCA196': precision_pca196}\n",
    "pd.DataFrame(data = d_precision_pcaVSrdnforrest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we do much better with pca196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Recall for pca196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 63, 289, 556, 277, 134, 56, 446, 306, 57]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN_pca196 = [0] * 10\n",
    "\n",
    "for i in range (len(FN_pca196)):\n",
    "    for j in range (len(FN_pca196)):\n",
    "        if i != j:\n",
    "            FN_pca196[i] += confusion_matrix[i][j]\n",
    "\n",
    "FN_pca196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9338598223099703,\n",
       " 0.9452173913043478,\n",
       " 0.7638888888888888,\n",
       " 0.6230508474576271,\n",
       " 0.7585004359197908,\n",
       " 0.8441860465116279,\n",
       " 0.9419689119170984,\n",
       " 0.679136690647482,\n",
       " 0.7260519247985676,\n",
       " 0.9393617021276596]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_pca196 = [0] * 10\n",
    "\n",
    "for i in range (len(recall_pca196)):\n",
    "    recall_pca196[i] = TP_pca196[i] / (TP_pca196[i] + FN_pca196[i])\n",
    "\n",
    "recall_pca196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForrest</th>\n",
       "      <th>PCA196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931633</td>\n",
       "      <td>0.933860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944493</td>\n",
       "      <td>0.945217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719961</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.449505</td>\n",
       "      <td>0.623051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717923</td>\n",
       "      <td>0.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.849776</td>\n",
       "      <td>0.844186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.941545</td>\n",
       "      <td>0.941969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.566148</td>\n",
       "      <td>0.679137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.685832</td>\n",
       "      <td>0.726052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.943508</td>\n",
       "      <td>0.939362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForrest    PCA196\n",
       "0       0.931633  0.933860\n",
       "1       0.944493  0.945217\n",
       "2       0.719961  0.763889\n",
       "3       0.449505  0.623051\n",
       "4       0.717923  0.758500\n",
       "5       0.849776  0.844186\n",
       "6       0.941545  0.941969\n",
       "7       0.566148  0.679137\n",
       "8       0.685832  0.726052\n",
       "9       0.943508  0.939362"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_recall_pcaVSrdnforrest = {'RandomForrest': recall, 'PCA196': recall_pca196}\n",
    "pd.DataFrame(data = d_recall_pcaVSrdnforrest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still somewhat do better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then also try the reduction that preserves just more than 80% of the variance and see how that performs in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_80per = PCA()\n",
    "pca_80per.fit(X_train)\n",
    "cumsum = np.cumsum(pca_80per.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.8) + 1\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure explained_variance_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cumsum, linewidth=3)\n",
    "plt.axis([0, 400, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([d, d], [0, 0.8], \"k:\")\n",
    "plt.plot([0, d], [0.8, 0.8], \"k:\")\n",
    "plt.plot(d, 0.8, \"ko\")\n",
    "\n",
    "plt.grid(True)\n",
    "save_fig(\"explained_variance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so to preserve just more than 80% of the variance, we only need to keep 44 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 44)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_80per = PCA(n_components = 0.8)\n",
    "\n",
    "X_train_80per = pca_80per.fit_transform(X_train)\n",
    "\n",
    "X_train_80per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032907553836799"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca_80per.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_pca80per_timer.fit took 12.665 secs to fit 60k obs, each with only 44 features\n"
     ]
    }
   ],
   "source": [
    "sgd_clf_pca80per = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "with elapsed_timer() as sgd_pca80per_timer:\n",
    "    sgd_clf_pca80per.fit(X_train_80per, y_train)\n",
    "print(f\"sgd_pca80per_timer.fit took {sgd_pca80per_timer():.3f} secs to fit 60k obs, each with only 44 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 44)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_80per = pca_80per.transform(X_test)\n",
    "X_test_pca_80per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pca_80per = sgd_clf_pca80per.predict(X_test_pca_80per)\n",
    "\n",
    "y_test_pca_80per.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for pca_80per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 945,    0,    1,    0,    1,   14,   13,    2,    4,    0],\n",
       "       [   0, 1086,    7,    3,    0,    1,    4,    1,   32,    1],\n",
       "       [  10,   17,  859,   32,   15,    0,   22,   15,   57,    5],\n",
       "       [   4,   10,   15,  908,    3,   21,    5,    6,   28,   10],\n",
       "       [   4,    4,    2,    3,  900,    2,   20,    2,    7,   38],\n",
       "       [  15,    7,    9,   63,   30,  695,   21,    9,   35,    8],\n",
       "       [  14,    4,    2,    1,    5,    8,  915,    6,    3,    0],\n",
       "       [   2,   18,   24,    6,   15,    2,    0,  928,    5,   28],\n",
       "       [  10,   29,   11,   38,    9,   33,   20,   14,  800,   10],\n",
       "       [  17,   18,    4,   13,   68,   16,    3,   58,   23,  789]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_pca80per = np.zeros((10,10))\n",
    "\n",
    "for i in range (len(y_test)):\n",
    "    confusion_matrix_pca80per[y_test[i]][y_test_pca_80per[i]] += 1\n",
    "    \n",
    "confusion_matrix_pca80per = confusion_matrix_pca80per.astype(int)\n",
    "confusion_matrix_pca80per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[945, 1086, 859, 908, 900, 695, 915, 928, 800, 789]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_pca80per = [0] * 10  \n",
    "\n",
    "for i in range (len(TP_pca80per)):\n",
    "    TP_pca80per[i] += confusion_matrix_pca80per[i][i]\n",
    "\n",
    "TP_pca80per "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PCA to reduce the dimension down so we can keep just 80 percent of variance, we get the accuracy of: 0.8825\n"
     ]
    }
   ],
   "source": [
    "pca80per_accuracy = np.sum(TP_pca80per) / 10000\n",
    "\n",
    "print(\"Using PCA to reduce the dimension down so we can keep just 80 percent of variance, we get the accuracy of: \" + str(pca80per_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get slightly lower accuracy compared to when we set the number of pixel as 196."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 107, 75, 159, 146, 97, 108, 113, 194, 100]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_pca80per = [0] * 10  \n",
    "\n",
    "for i in range (len(FP_pca80per)):\n",
    "    for j in range (len(FP_pca80per)):\n",
    "        if i != j:\n",
    "            FP_pca80per[i] += confusion_matrix_pca80per[j][i]\n",
    "\n",
    "FP_pca80per  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9255631733594515,\n",
       " 0.9103101424979044,\n",
       " 0.9197002141327623,\n",
       " 0.8509840674789129,\n",
       " 0.8604206500956023,\n",
       " 0.8775252525252525,\n",
       " 0.8944281524926686,\n",
       " 0.8914505283381364,\n",
       " 0.8048289738430584,\n",
       " 0.8875140607424072]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_pca80per = [0] * 10\n",
    "\n",
    "for i in range (len(precision_pca80per)):\n",
    "    precision_pca80per[i] = TP_pca80per[i] / (TP_pca80per[i] + FP_pca80per[i])\n",
    "\n",
    "precision_pca80per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForrest</th>\n",
       "      <th>PCA196</th>\n",
       "      <th>PCA80per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905754</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.925563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963163</td>\n",
       "      <td>0.972272</td>\n",
       "      <td>0.910310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.948914</td>\n",
       "      <td>0.898175</td>\n",
       "      <td>0.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959831</td>\n",
       "      <td>0.893969</td>\n",
       "      <td>0.850984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.924548</td>\n",
       "      <td>0.860421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.552076</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.879961</td>\n",
       "      <td>0.894428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984772</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>0.891451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.882481</td>\n",
       "      <td>0.804829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.530067</td>\n",
       "      <td>0.852317</td>\n",
       "      <td>0.887514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForrest    PCA196  PCA80per\n",
       "0       0.905754  0.956522  0.925563\n",
       "1       0.963163  0.972272  0.910310\n",
       "2       0.948914  0.898175  0.919700\n",
       "3       0.959831  0.893969  0.850984\n",
       "4       0.883459  0.924548  0.860421\n",
       "5       0.552076  0.889706  0.877525\n",
       "6       0.796117  0.879961  0.894428\n",
       "7       0.984772  0.874884  0.891451\n",
       "8       0.716738  0.882481  0.804829\n",
       "9       0.530067  0.852317  0.887514"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_precision_pcaVSrdnforrest_VS_pca80per = {'RandomForrest': precision, 'PCA196': precision_pca196, 'PCA80per': precision_pca80per}\n",
    "pd.DataFrame(data = d_precision_pcaVSrdnforrest_VS_pca80per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, 2 PCA methods did not yield that much of a difference in precision. I will not compute recall because we can expect a roughly the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Lab 4"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {},
  "nteract": {
   "version": "0.15.0"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
